{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d1efb93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from wav2lip import Wav2Lip\n",
    "from conv import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "151d6139",
   "metadata": {},
   "outputs": [],
   "source": [
    "fuse_counter = 0\n",
    "\n",
    "def fuse_conv_bn_eval(conv, bn):\n",
    "    \"\"\"\n",
    "    Fuse a Conv2d (or ConvTranspose2d) and BatchNorm2d into a single layer.\n",
    "    Both modules must be in eval() mode.\n",
    "    \"\"\"\n",
    "    assert isinstance(conv, (nn.Conv2d, nn.ConvTranspose2d)), \"Only Conv2d or ConvTranspose2d is supported!\"\n",
    "    assert isinstance(bn, nn.BatchNorm2d), \"Only BatchNorm2d is supported!\"\n",
    "\n",
    "    # Выбираем правильный класс\n",
    "    fused_cls = type(conv)\n",
    "\n",
    "    # Подготовка общих аргументов\n",
    "    common_kwargs = dict(\n",
    "        in_channels=conv.in_channels,\n",
    "        out_channels=conv.out_channels,\n",
    "        kernel_size=conv.kernel_size,\n",
    "        stride=conv.stride,\n",
    "        padding=conv.padding,\n",
    "        dilation=conv.dilation,\n",
    "        groups=conv.groups,\n",
    "        bias=True,\n",
    "    )\n",
    "\n",
    "    # Для ConvTranspose2d нужно добавить output_padding\n",
    "    if isinstance(conv, nn.ConvTranspose2d):\n",
    "        common_kwargs[\"output_padding\"] = conv.output_padding\n",
    "\n",
    "    # padding_mode есть только у Conv2d\n",
    "    if isinstance(conv, nn.Conv2d):\n",
    "        common_kwargs[\"padding_mode\"] = conv.padding_mode\n",
    "\n",
    "    # Новый слой\n",
    "    fused_conv = fused_cls(**common_kwargs)\n",
    "\n",
    "    # Параметры\n",
    "    w_conv = conv.weight.clone()\n",
    "    if conv.bias is not None:\n",
    "        b_conv = conv.bias.clone()\n",
    "    else:\n",
    "        b_conv = torch.zeros(conv.out_channels, device=w_conv.device)\n",
    "\n",
    "    w_bn = bn.weight\n",
    "    b_bn = bn.bias\n",
    "    running_mean = bn.running_mean\n",
    "    running_var = bn.running_var\n",
    "    eps = bn.eps\n",
    "\n",
    "    scale = w_bn / torch.sqrt(running_var + eps)\n",
    "\n",
    "    if isinstance(conv, nn.Conv2d):\n",
    "        # scale по out_channels\n",
    "        w_conv_fused = w_conv * scale.reshape([-1, 1, 1, 1])\n",
    "        b_conv_fused = b_bn + (b_conv - running_mean) * scale\n",
    "    elif isinstance(conv, nn.ConvTranspose2d):\n",
    "        # scale по in_channels\n",
    "        w_conv_fused = w_conv * scale.reshape([1, -1, 1, 1])\n",
    "        b_conv_fused = b_bn + (b_conv - running_mean) * scale\n",
    "\n",
    "    # Обновляем веса\n",
    "    fused_conv.weight.data.copy_(w_conv_fused)\n",
    "    fused_conv.bias.data.copy_(b_conv_fused)\n",
    "\n",
    "    return fused_conv\n",
    "\n",
    "\n",
    "def fuse_model_eval(model):\n",
    "    global fuse_counter\n",
    "    \"\"\"\n",
    "    Рекурсивно проходит по модулям модели.\n",
    "    Там, где видит Conv2d + BatchNorm2d, заменяет их на эквивалентный Conv2d.\n",
    "    Работает только в eval() режиме.\n",
    "    \"\"\"\n",
    "    for name, module in model.named_children():\n",
    "        # Если в модуле есть атрибут conv_block\n",
    "        if hasattr(module, \"conv_block\") and isinstance(module.conv_block, nn.Sequential):\n",
    "            modules = list(module.conv_block.children())\n",
    "            new_modules = []\n",
    "            skip = False\n",
    "            for i in range(len(modules)):\n",
    "                if skip:\n",
    "                    skip = False\n",
    "                    continue\n",
    "                if (\n",
    "                    (isinstance(modules[i], nn.Conv2d) or isinstance(modules[i], nn.ConvTranspose2d))\n",
    "                    and i + 1 < len(modules)\n",
    "                    and isinstance(modules[i + 1], nn.BatchNorm2d)\n",
    "                ):\n",
    "                    # Fuse!\n",
    "                    fused_conv = fuse_conv_bn_eval(modules[i], modules[i + 1])\n",
    "                    new_modules.append(fused_conv)\n",
    "                    skip = True  # Пропускаем BatchNorm2d\n",
    "                    fuse_counter += 1\n",
    "                else:\n",
    "                    new_modules.append(modules[i])\n",
    "            # Обновляем conv_block\n",
    "            module.conv_block = nn.Sequential(*new_modules)\n",
    "        \n",
    "        # Рекурсивно вызываем для всех детей\n",
    "        fuse_model_eval(module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "edffcd41",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def one_step(model, mel, face, device):\n",
    "    with torch.no_grad():\n",
    "        torch.cuda.reset_peak_memory_stats(device)\n",
    "        out = model(mel, face)\n",
    "        print(\"Peak memory (MB):\", torch.cuda.max_memory_allocated(device) / 1024**2)\n",
    "\n",
    "def test_fusing(do_fuse, device, batch_size):\n",
    "    global fuse_counter\n",
    "    model = Wav2Lip()\n",
    "    mel = torch.rand(batch_size, 1, 80, 16)\n",
    "    face = torch.rand(batch_size, 6, 96, 96)\n",
    "    model.eval()\n",
    "\n",
    "    if do_fuse:\n",
    "        fuse_model_eval(model)\n",
    "        print(\"Fusing done. Number of fused layers: {}\".format(fuse_counter))\n",
    "    model = model.to(device)\n",
    "    mel = mel.to(device)\n",
    "    face = face.to(device)\n",
    "    one_step(model, mel, face, device)\n",
    "\n",
    "def test_time_for_fusing(do_fuse, device, batch_size):\n",
    "    import time\n",
    "    import numpy as np\n",
    "    mean_time = []\n",
    "    global fuse_counter\n",
    "    model = Wav2Lip()\n",
    "    mel = torch.rand(batch_size, 1, 80, 16)\n",
    "    face = torch.rand(batch_size, 6, 96, 96)\n",
    "    model.eval()\n",
    "\n",
    "    if do_fuse:\n",
    "        fuse_model_eval(model)\n",
    "        print(\"Fusing done. Number of fused layers: {}\".format(fuse_counter))\n",
    "    model = model.to(device)\n",
    "    mel = mel.to(device)\n",
    "    face = face.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for _ in range(100):\n",
    "            start = time.time()\n",
    "            out = model(mel, face)\n",
    "            mean_time.append(time.time() - start)\n",
    "    print(\"Total time: {}, mean time: {}\".format(np.sum(mean_time), np.mean(mean_time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b997360",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time: 1.1565561294555664, mean time: 0.011565561294555665\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# test_fusing(True, \"cuda\", 1)\n",
    "# test_time_for_fusing(True, \"cuda\", 1)\n",
    "\n",
    "# test_fusing(False, \"cuda\", 1)\n",
    "test_time_for_fusing(False, \"cuda\", 1)\n",
    "\n",
    "# Memory:\n",
    "#    FUSE: Peak memory (MB): 161.12353515625 (Number of fused layers: 50)\n",
    "# NO FUSE: Peak memory (MB): 161.34326171875\n",
    "\n",
    "# Speed:\n",
    "#    FUSE: Total time: 0.9142956733703613, mean time: 0.009142956733703612\n",
    "# NO FUSE: Total time: 1.1565561294555664, mean time: 0.011565561294555665"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
